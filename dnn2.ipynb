{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv('./dts/train.csv')\n",
    "test_df = pd.read_csv('./dts/test.csv')\n",
    "sample_submission_df = pd.read_csv('./dts/sample_submission.csv')\n",
    "\n",
    "# ID 열 제거\n",
    "train_df = train_df.drop('ID', axis=1)\n",
    "test_df = test_df.drop('ID', axis=1)\n",
    "\n",
    "# Weight_Status, Gender 열을 숫자 데이터로 변환\n",
    "train_df['Weight_Status'] = train_df['Weight_Status'].map({'Normal Weight': 0, 'Overweight': 1, 'Obese': 2})\n",
    "train_df['Gender'] = train_df['Gender'].map({'M': 0, 'F': 1})\n",
    "test_df['Weight_Status'] = test_df['Weight_Status'].map({'Normal Weight': 0, 'Overweight': 1, 'Obese': 2})\n",
    "test_df['Gender'] = test_df['Gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# PolynomialFeatures를 사용하여 데이터 전처리\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X = poly.fit_transform(train_df.drop('Calories_Burned', axis=1))\n",
    "y = train_df['Calories_Burned']\n",
    "\n",
    "# 표준화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train, valid 데이터 나누기\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250, 54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "165/165 [==============================] - 1s 1ms/step - loss: 104.1090 - val_loss: 95.0061\n",
      "Epoch 2/1000\n",
      "165/165 [==============================] - 0s 757us/step - loss: 78.6812 - val_loss: 58.1013\n",
      "Epoch 3/1000\n",
      "165/165 [==============================] - 0s 733us/step - loss: 37.2957 - val_loss: 21.2240\n",
      "Epoch 4/1000\n",
      "165/165 [==============================] - 0s 747us/step - loss: 17.1975 - val_loss: 13.8521\n",
      "Epoch 5/1000\n",
      "165/165 [==============================] - 0s 810us/step - loss: 11.9220 - val_loss: 9.8381\n",
      "Epoch 6/1000\n",
      "165/165 [==============================] - 0s 730us/step - loss: 8.8533 - val_loss: 7.6477\n",
      "Epoch 7/1000\n",
      "165/165 [==============================] - 0s 763us/step - loss: 6.9558 - val_loss: 6.1513\n",
      "Epoch 8/1000\n",
      "165/165 [==============================] - 0s 758us/step - loss: 5.7702 - val_loss: 5.1899\n",
      "Epoch 9/1000\n",
      "165/165 [==============================] - 0s 761us/step - loss: 4.8502 - val_loss: 4.4034\n",
      "Epoch 10/1000\n",
      "165/165 [==============================] - 0s 744us/step - loss: 4.1348 - val_loss: 3.8684\n",
      "Epoch 11/1000\n",
      "165/165 [==============================] - 0s 747us/step - loss: 3.5600 - val_loss: 3.3121\n",
      "Epoch 12/1000\n",
      "165/165 [==============================] - 0s 757us/step - loss: 3.1283 - val_loss: 2.9683\n",
      "Epoch 13/1000\n",
      "165/165 [==============================] - 0s 755us/step - loss: 2.7764 - val_loss: 2.6304\n",
      "Epoch 14/1000\n",
      "165/165 [==============================] - 0s 750us/step - loss: 2.5044 - val_loss: 2.4318\n",
      "Epoch 15/1000\n",
      "165/165 [==============================] - 0s 755us/step - loss: 2.2957 - val_loss: 2.2398\n",
      "Epoch 16/1000\n",
      "165/165 [==============================] - 0s 824us/step - loss: 2.1384 - val_loss: 2.1083\n",
      "Epoch 17/1000\n",
      "165/165 [==============================] - 0s 729us/step - loss: 2.0161 - val_loss: 1.9512\n",
      "Epoch 18/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 1.9067 - val_loss: 1.8880\n",
      "Epoch 19/1000\n",
      "165/165 [==============================] - 0s 729us/step - loss: 1.8042 - val_loss: 1.8141\n",
      "Epoch 20/1000\n",
      "165/165 [==============================] - 0s 713us/step - loss: 1.7082 - val_loss: 1.6993\n",
      "Epoch 21/1000\n",
      "165/165 [==============================] - 0s 761us/step - loss: 1.6499 - val_loss: 1.6530\n",
      "Epoch 22/1000\n",
      "165/165 [==============================] - 0s 709us/step - loss: 1.5828 - val_loss: 1.5989\n",
      "Epoch 23/1000\n",
      "165/165 [==============================] - 0s 730us/step - loss: 1.5033 - val_loss: 1.4928\n",
      "Epoch 24/1000\n",
      "165/165 [==============================] - 0s 673us/step - loss: 1.4495 - val_loss: 1.5226\n",
      "Epoch 25/1000\n",
      "165/165 [==============================] - 0s 795us/step - loss: 1.3860 - val_loss: 1.3964\n",
      "Epoch 26/1000\n",
      "165/165 [==============================] - 0s 730us/step - loss: 1.3258 - val_loss: 1.3784\n",
      "Epoch 27/1000\n",
      "165/165 [==============================] - 0s 721us/step - loss: 1.2836 - val_loss: 1.3024\n",
      "Epoch 28/1000\n",
      "165/165 [==============================] - 0s 719us/step - loss: 1.2375 - val_loss: 1.2484\n",
      "Epoch 29/1000\n",
      "165/165 [==============================] - 0s 828us/step - loss: 1.1739 - val_loss: 1.2347\n",
      "Epoch 30/1000\n",
      "165/165 [==============================] - 0s 752us/step - loss: 1.1499 - val_loss: 1.2066\n",
      "Epoch 31/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 1.1130 - val_loss: 1.2186\n",
      "Epoch 32/1000\n",
      "165/165 [==============================] - 0s 716us/step - loss: 1.1001 - val_loss: 1.1435\n",
      "Epoch 33/1000\n",
      "165/165 [==============================] - 0s 744us/step - loss: 1.0615 - val_loss: 1.0745\n",
      "Epoch 34/1000\n",
      "165/165 [==============================] - 0s 730us/step - loss: 1.0385 - val_loss: 1.0525\n",
      "Epoch 35/1000\n",
      "165/165 [==============================] - 0s 680us/step - loss: 1.0177 - val_loss: 1.0628\n",
      "Epoch 36/1000\n",
      "165/165 [==============================] - 0s 676us/step - loss: 1.0106 - val_loss: 1.0975\n",
      "Epoch 37/1000\n",
      "165/165 [==============================] - 0s 811us/step - loss: 0.9835 - val_loss: 0.9996\n",
      "Epoch 38/1000\n",
      "165/165 [==============================] - 0s 759us/step - loss: 0.9518 - val_loss: 0.9927\n",
      "Epoch 39/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.9497 - val_loss: 0.9995\n",
      "Epoch 40/1000\n",
      "165/165 [==============================] - 0s 829us/step - loss: 0.9351 - val_loss: 0.9906\n",
      "Epoch 41/1000\n",
      "165/165 [==============================] - 0s 755us/step - loss: 0.9060 - val_loss: 0.9472\n",
      "Epoch 42/1000\n",
      "165/165 [==============================] - 0s 761us/step - loss: 0.8936 - val_loss: 0.9205\n",
      "Epoch 43/1000\n",
      "165/165 [==============================] - 0s 702us/step - loss: 0.8863 - val_loss: 0.9448\n",
      "Epoch 44/1000\n",
      "165/165 [==============================] - 0s 761us/step - loss: 0.8756 - val_loss: 0.9442\n",
      "Epoch 45/1000\n",
      "165/165 [==============================] - 0s 814us/step - loss: 0.8745 - val_loss: 0.8627\n",
      "Epoch 46/1000\n",
      "165/165 [==============================] - 0s 693us/step - loss: 0.8547 - val_loss: 0.9100\n",
      "Epoch 47/1000\n",
      "165/165 [==============================] - 0s 696us/step - loss: 0.8368 - val_loss: 0.8886\n",
      "Epoch 48/1000\n",
      "165/165 [==============================] - 0s 746us/step - loss: 0.8423 - val_loss: 0.8389\n",
      "Epoch 49/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.8143 - val_loss: 0.9049\n",
      "Epoch 50/1000\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.8291 - val_loss: 0.9116\n",
      "Epoch 51/1000\n",
      "165/165 [==============================] - 0s 793us/step - loss: 0.8067 - val_loss: 0.8285\n",
      "Epoch 52/1000\n",
      "165/165 [==============================] - 0s 774us/step - loss: 0.8030 - val_loss: 0.8193\n",
      "Epoch 53/1000\n",
      "165/165 [==============================] - 0s 692us/step - loss: 0.7934 - val_loss: 0.8647\n",
      "Epoch 54/1000\n",
      "165/165 [==============================] - 0s 714us/step - loss: 0.7849 - val_loss: 0.8469\n",
      "Epoch 55/1000\n",
      "165/165 [==============================] - 0s 775us/step - loss: 0.7655 - val_loss: 0.8029\n",
      "Epoch 56/1000\n",
      "165/165 [==============================] - 0s 687us/step - loss: 0.7643 - val_loss: 0.8068\n",
      "Epoch 57/1000\n",
      "165/165 [==============================] - 0s 795us/step - loss: 0.7655 - val_loss: 0.7769\n",
      "Epoch 58/1000\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.7470 - val_loss: 0.7864\n",
      "Epoch 59/1000\n",
      "165/165 [==============================] - 0s 791us/step - loss: 0.7412 - val_loss: 0.7634\n",
      "Epoch 60/1000\n",
      "165/165 [==============================] - 0s 702us/step - loss: 0.7329 - val_loss: 0.8189\n",
      "Epoch 61/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.7283 - val_loss: 0.7892\n",
      "Epoch 62/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.7270 - val_loss: 0.7812\n",
      "Epoch 63/1000\n",
      "165/165 [==============================] - 0s 762us/step - loss: 0.7096 - val_loss: 0.7655\n",
      "Epoch 64/1000\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.7255 - val_loss: 0.7683\n",
      "Epoch 65/1000\n",
      "165/165 [==============================] - 0s 699us/step - loss: 0.7161 - val_loss: 0.7676\n",
      "Epoch 66/1000\n",
      "165/165 [==============================] - 0s 794us/step - loss: 0.7068 - val_loss: 0.7585\n",
      "Epoch 67/1000\n",
      "165/165 [==============================] - 0s 749us/step - loss: 0.6872 - val_loss: 0.7552\n",
      "Epoch 68/1000\n",
      "165/165 [==============================] - 0s 754us/step - loss: 0.6844 - val_loss: 0.7288\n",
      "Epoch 69/1000\n",
      "165/165 [==============================] - 0s 668us/step - loss: 0.6776 - val_loss: 0.7368\n",
      "Epoch 70/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.6678 - val_loss: 0.7365\n",
      "Epoch 71/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.6660 - val_loss: 0.7521\n",
      "Epoch 72/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.6710 - val_loss: 0.8370\n",
      "Epoch 73/1000\n",
      "165/165 [==============================] - 0s 697us/step - loss: 0.6730 - val_loss: 0.8364\n",
      "Epoch 74/1000\n",
      "165/165 [==============================] - 0s 685us/step - loss: 0.6753 - val_loss: 0.7956\n",
      "Epoch 75/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.6689 - val_loss: 0.7714\n",
      "Epoch 76/1000\n",
      "165/165 [==============================] - 0s 777us/step - loss: 0.6679 - val_loss: 0.7088\n",
      "Epoch 77/1000\n",
      "165/165 [==============================] - 0s 692us/step - loss: 0.6538 - val_loss: 0.7324\n",
      "Epoch 78/1000\n",
      "165/165 [==============================] - 0s 680us/step - loss: 0.6500 - val_loss: 0.7428\n",
      "Epoch 79/1000\n",
      "165/165 [==============================] - 0s 793us/step - loss: 0.6345 - val_loss: 0.7080\n",
      "Epoch 80/1000\n",
      "165/165 [==============================] - 0s 688us/step - loss: 0.6479 - val_loss: 0.7444\n",
      "Epoch 81/1000\n",
      "165/165 [==============================] - 0s 808us/step - loss: 0.6463 - val_loss: 0.7006\n",
      "Epoch 82/1000\n",
      "165/165 [==============================] - 0s 757us/step - loss: 0.6285 - val_loss: 0.7535\n",
      "Epoch 83/1000\n",
      "165/165 [==============================] - 0s 794us/step - loss: 0.6282 - val_loss: 0.6738\n",
      "Epoch 84/1000\n",
      "165/165 [==============================] - 0s 710us/step - loss: 0.6240 - val_loss: 0.7177\n",
      "Epoch 85/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.6147 - val_loss: 0.6821\n",
      "Epoch 86/1000\n",
      "165/165 [==============================] - 0s 679us/step - loss: 0.6140 - val_loss: 0.6810\n",
      "Epoch 87/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.6154 - val_loss: 0.7200\n",
      "Epoch 88/1000\n",
      "165/165 [==============================] - 0s 687us/step - loss: 0.6113 - val_loss: 0.6828\n",
      "Epoch 89/1000\n",
      "165/165 [==============================] - 0s 687us/step - loss: 0.6111 - val_loss: 0.7267\n",
      "Epoch 90/1000\n",
      "165/165 [==============================] - 0s 679us/step - loss: 0.6050 - val_loss: 0.6910\n",
      "Epoch 91/1000\n",
      "165/165 [==============================] - 0s 797us/step - loss: 0.6139 - val_loss: 0.6724\n",
      "Epoch 92/1000\n",
      "165/165 [==============================] - 0s 751us/step - loss: 0.6079 - val_loss: 0.6854\n",
      "Epoch 93/1000\n",
      "165/165 [==============================] - 0s 697us/step - loss: 0.5885 - val_loss: 0.7221\n",
      "Epoch 94/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.6108 - val_loss: 0.7847\n",
      "Epoch 95/1000\n",
      "165/165 [==============================] - 0s 688us/step - loss: 0.5967 - val_loss: 0.6828\n",
      "Epoch 96/1000\n",
      "165/165 [==============================] - 0s 755us/step - loss: 0.6017 - val_loss: 0.6604\n",
      "Epoch 97/1000\n",
      "165/165 [==============================] - 0s 698us/step - loss: 0.6021 - val_loss: 0.6663\n",
      "Epoch 98/1000\n",
      "165/165 [==============================] - 0s 661us/step - loss: 0.5898 - val_loss: 0.6759\n",
      "Epoch 99/1000\n",
      "165/165 [==============================] - 0s 738us/step - loss: 0.5948 - val_loss: 0.6753\n",
      "Epoch 100/1000\n",
      "165/165 [==============================] - 0s 688us/step - loss: 0.5817 - val_loss: 0.6704\n",
      "Epoch 101/1000\n",
      "165/165 [==============================] - 0s 685us/step - loss: 0.5856 - val_loss: 0.7026\n",
      "Epoch 102/1000\n",
      "165/165 [==============================] - 0s 789us/step - loss: 0.5882 - val_loss: 0.6498\n",
      "Epoch 103/1000\n",
      "165/165 [==============================] - 0s 687us/step - loss: 0.5781 - val_loss: 0.6613\n",
      "Epoch 104/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.5898 - val_loss: 0.6748\n",
      "Epoch 105/1000\n",
      "165/165 [==============================] - 0s 687us/step - loss: 0.5763 - val_loss: 0.6880\n",
      "Epoch 106/1000\n",
      "165/165 [==============================] - 0s 781us/step - loss: 0.5825 - val_loss: 0.6414\n",
      "Epoch 107/1000\n",
      "165/165 [==============================] - 0s 699us/step - loss: 0.5697 - val_loss: 0.6476\n",
      "Epoch 108/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.5644 - val_loss: 0.6567\n",
      "Epoch 109/1000\n",
      "165/165 [==============================] - 0s 790us/step - loss: 0.5719 - val_loss: 0.6310\n",
      "Epoch 110/1000\n",
      "165/165 [==============================] - 0s 696us/step - loss: 0.5635 - val_loss: 0.6585\n",
      "Epoch 111/1000\n",
      "165/165 [==============================] - 0s 712us/step - loss: 0.5670 - val_loss: 0.6559\n",
      "Epoch 112/1000\n",
      "165/165 [==============================] - 0s 680us/step - loss: 0.5680 - val_loss: 0.7081\n",
      "Epoch 113/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.5635 - val_loss: 0.6512\n",
      "Epoch 114/1000\n",
      "165/165 [==============================] - 0s 704us/step - loss: 0.5647 - val_loss: 0.7231\n",
      "Epoch 115/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.5696 - val_loss: 0.6710\n",
      "Epoch 116/1000\n",
      "165/165 [==============================] - 0s 708us/step - loss: 0.5646 - val_loss: 0.6384\n",
      "Epoch 117/1000\n",
      "165/165 [==============================] - 0s 769us/step - loss: 0.5529 - val_loss: 0.6408\n",
      "Epoch 118/1000\n",
      "165/165 [==============================] - 0s 709us/step - loss: 0.5643 - val_loss: 0.6936\n",
      "Epoch 119/1000\n",
      "165/165 [==============================] - 0s 845us/step - loss: 0.5536 - val_loss: 0.6098\n",
      "Epoch 120/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.5512 - val_loss: 0.6764\n",
      "Epoch 121/1000\n",
      "165/165 [==============================] - 0s 704us/step - loss: 0.5561 - val_loss: 0.6604\n",
      "Epoch 122/1000\n",
      "165/165 [==============================] - 0s 711us/step - loss: 0.5592 - val_loss: 0.6534\n",
      "Epoch 123/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.5472 - val_loss: 0.6633\n",
      "Epoch 124/1000\n",
      "165/165 [==============================] - 0s 730us/step - loss: 0.5470 - val_loss: 0.6177\n",
      "Epoch 125/1000\n",
      "165/165 [==============================] - 0s 698us/step - loss: 0.5511 - val_loss: 0.6114\n",
      "Epoch 126/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.5355 - val_loss: 0.6336\n",
      "Epoch 127/1000\n",
      "165/165 [==============================] - 0s 708us/step - loss: 0.5569 - val_loss: 0.6560\n",
      "Epoch 128/1000\n",
      "165/165 [==============================] - 0s 709us/step - loss: 0.5471 - val_loss: 0.6261\n",
      "Epoch 129/1000\n",
      "165/165 [==============================] - 0s 711us/step - loss: 0.5337 - val_loss: 0.6397\n",
      "Epoch 130/1000\n",
      "165/165 [==============================] - 0s 697us/step - loss: 0.5418 - val_loss: 0.6608\n",
      "Epoch 131/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.5494 - val_loss: 0.6210\n",
      "Epoch 132/1000\n",
      "165/165 [==============================] - 0s 697us/step - loss: 0.5363 - val_loss: 0.6276\n",
      "Epoch 133/1000\n",
      "165/165 [==============================] - 0s 699us/step - loss: 0.5340 - val_loss: 0.6371\n",
      "Epoch 134/1000\n",
      "165/165 [==============================] - 0s 774us/step - loss: 0.5274 - val_loss: 0.6277\n",
      "Epoch 135/1000\n",
      "165/165 [==============================] - 0s 704us/step - loss: 0.5432 - val_loss: 0.6755\n",
      "Epoch 136/1000\n",
      "165/165 [==============================] - 0s 781us/step - loss: 0.5501 - val_loss: 0.6066\n",
      "Epoch 137/1000\n",
      "165/165 [==============================] - 0s 682us/step - loss: 0.5248 - val_loss: 0.6258\n",
      "Epoch 138/1000\n",
      "165/165 [==============================] - 0s 725us/step - loss: 0.5276 - val_loss: 0.6661\n",
      "Epoch 139/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.5332 - val_loss: 0.6295\n",
      "Epoch 140/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.5317 - val_loss: 0.6477\n",
      "Epoch 141/1000\n",
      "165/165 [==============================] - 0s 708us/step - loss: 0.5319 - val_loss: 0.6384\n",
      "Epoch 142/1000\n",
      "165/165 [==============================] - 0s 877us/step - loss: 0.5263 - val_loss: 0.6023\n",
      "Epoch 143/1000\n",
      "165/165 [==============================] - 0s 700us/step - loss: 0.5286 - val_loss: 0.6598\n",
      "Epoch 144/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.5259 - val_loss: 0.6385\n",
      "Epoch 145/1000\n",
      "165/165 [==============================] - 0s 755us/step - loss: 0.5159 - val_loss: 0.5936\n",
      "Epoch 146/1000\n",
      "165/165 [==============================] - 0s 698us/step - loss: 0.5146 - val_loss: 0.6197\n",
      "Epoch 147/1000\n",
      "165/165 [==============================] - 0s 696us/step - loss: 0.5267 - val_loss: 0.6216\n",
      "Epoch 148/1000\n",
      "165/165 [==============================] - 0s 704us/step - loss: 0.5292 - val_loss: 0.6044\n",
      "Epoch 149/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.5072 - val_loss: 0.5991\n",
      "Epoch 150/1000\n",
      "165/165 [==============================] - 0s 729us/step - loss: 0.5181 - val_loss: 0.5986\n",
      "Epoch 151/1000\n",
      "165/165 [==============================] - 0s 873us/step - loss: 0.5225 - val_loss: 0.5689\n",
      "Epoch 152/1000\n",
      "165/165 [==============================] - 0s 712us/step - loss: 0.5197 - val_loss: 0.6127\n",
      "Epoch 153/1000\n",
      "165/165 [==============================] - 0s 692us/step - loss: 0.5149 - val_loss: 0.5965\n",
      "Epoch 154/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.5194 - val_loss: 0.5744\n",
      "Epoch 155/1000\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.5188 - val_loss: 0.5931\n",
      "Epoch 156/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.5194 - val_loss: 0.5965\n",
      "Epoch 157/1000\n",
      "165/165 [==============================] - 0s 713us/step - loss: 0.5250 - val_loss: 0.6228\n",
      "Epoch 158/1000\n",
      "165/165 [==============================] - 0s 681us/step - loss: 0.5184 - val_loss: 0.6452\n",
      "Epoch 159/1000\n",
      "165/165 [==============================] - 0s 681us/step - loss: 0.5240 - val_loss: 0.6498\n",
      "Epoch 160/1000\n",
      "165/165 [==============================] - 0s 681us/step - loss: 0.5095 - val_loss: 0.5966\n",
      "Epoch 161/1000\n",
      "165/165 [==============================] - 0s 681us/step - loss: 0.5085 - val_loss: 0.6178\n",
      "Epoch 162/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.5053 - val_loss: 0.6017\n",
      "Epoch 163/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.5100 - val_loss: 0.5836\n",
      "Epoch 164/1000\n",
      "165/165 [==============================] - 0s 678us/step - loss: 0.5113 - val_loss: 0.6033\n",
      "Epoch 165/1000\n",
      "165/165 [==============================] - 0s 783us/step - loss: 0.5166 - val_loss: 0.5684\n",
      "Epoch 166/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.5026 - val_loss: 0.6999\n",
      "Epoch 167/1000\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.5177 - val_loss: 0.5854\n",
      "Epoch 168/1000\n",
      "165/165 [==============================] - 0s 764us/step - loss: 0.5128 - val_loss: 0.5795\n",
      "Epoch 169/1000\n",
      "165/165 [==============================] - 0s 745us/step - loss: 0.4999 - val_loss: 0.5544\n",
      "Epoch 170/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4975 - val_loss: 0.5903\n",
      "Epoch 171/1000\n",
      "165/165 [==============================] - 0s 686us/step - loss: 0.5154 - val_loss: 0.6119\n",
      "Epoch 172/1000\n",
      "165/165 [==============================] - 0s 665us/step - loss: 0.4917 - val_loss: 0.6018\n",
      "Epoch 173/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.5103 - val_loss: 0.6362\n",
      "Epoch 174/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.5117 - val_loss: 0.6097\n",
      "Epoch 175/1000\n",
      "165/165 [==============================] - 0s 681us/step - loss: 0.5206 - val_loss: 0.6152\n",
      "Epoch 176/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.5045 - val_loss: 0.5794\n",
      "Epoch 177/1000\n",
      "165/165 [==============================] - 0s 686us/step - loss: 0.5013 - val_loss: 0.5674\n",
      "Epoch 178/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4932 - val_loss: 0.6016\n",
      "Epoch 179/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4983 - val_loss: 0.6502\n",
      "Epoch 180/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.5120 - val_loss: 0.5926\n",
      "Epoch 181/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4954 - val_loss: 0.5902\n",
      "Epoch 182/1000\n",
      "165/165 [==============================] - 0s 665us/step - loss: 0.4960 - val_loss: 0.5974\n",
      "Epoch 183/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.5026 - val_loss: 0.6024\n",
      "Epoch 184/1000\n",
      "165/165 [==============================] - 0s 750us/step - loss: 0.4919 - val_loss: 0.6054\n",
      "Epoch 185/1000\n",
      "165/165 [==============================] - 0s 692us/step - loss: 0.5009 - val_loss: 0.5755\n",
      "Epoch 186/1000\n",
      "165/165 [==============================] - 0s 665us/step - loss: 0.4879 - val_loss: 0.5934\n",
      "Epoch 187/1000\n",
      "165/165 [==============================] - 0s 678us/step - loss: 0.4955 - val_loss: 0.6439\n",
      "Epoch 188/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4932 - val_loss: 0.5990\n",
      "Epoch 189/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.5008 - val_loss: 0.5561\n",
      "Epoch 190/1000\n",
      "165/165 [==============================] - 0s 659us/step - loss: 0.5045 - val_loss: 0.6246\n",
      "Epoch 191/1000\n",
      "165/165 [==============================] - 0s 715us/step - loss: 0.4903 - val_loss: 0.5612\n",
      "Epoch 192/1000\n",
      "165/165 [==============================] - 0s 682us/step - loss: 0.4888 - val_loss: 0.5839\n",
      "Epoch 193/1000\n",
      "165/165 [==============================] - 0s 680us/step - loss: 0.4943 - val_loss: 0.5945\n",
      "Epoch 194/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4879 - val_loss: 0.5691\n",
      "Epoch 195/1000\n",
      "165/165 [==============================] - 0s 653us/step - loss: 0.4928 - val_loss: 0.6276\n",
      "Epoch 196/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.4911 - val_loss: 0.5562\n",
      "Epoch 197/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4981 - val_loss: 0.6854\n",
      "Epoch 198/1000\n",
      "165/165 [==============================] - 0s 750us/step - loss: 0.4853 - val_loss: 0.5786\n",
      "Epoch 199/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4847 - val_loss: 0.5589\n",
      "Epoch 200/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4819 - val_loss: 0.6327\n",
      "Epoch 201/1000\n",
      "165/165 [==============================] - 0s 696us/step - loss: 0.4878 - val_loss: 0.5880\n",
      "Epoch 202/1000\n",
      "165/165 [==============================] - 0s 713us/step - loss: 0.4884 - val_loss: 0.5761\n",
      "Epoch 203/1000\n",
      "165/165 [==============================] - 0s 803us/step - loss: 0.4788 - val_loss: 0.5531\n",
      "Epoch 204/1000\n",
      "165/165 [==============================] - 0s 762us/step - loss: 0.4957 - val_loss: 0.5479\n",
      "Epoch 205/1000\n",
      "165/165 [==============================] - 0s 764us/step - loss: 0.4702 - val_loss: 0.5475\n",
      "Epoch 206/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4726 - val_loss: 0.5610\n",
      "Epoch 207/1000\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.4772 - val_loss: 0.5634\n",
      "Epoch 208/1000\n",
      "165/165 [==============================] - 0s 796us/step - loss: 0.4870 - val_loss: 0.5447\n",
      "Epoch 209/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4891 - val_loss: 0.5463\n",
      "Epoch 210/1000\n",
      "165/165 [==============================] - 0s 693us/step - loss: 0.4716 - val_loss: 0.5813\n",
      "Epoch 211/1000\n",
      "165/165 [==============================] - 0s 702us/step - loss: 0.4737 - val_loss: 0.6050\n",
      "Epoch 212/1000\n",
      "165/165 [==============================] - 0s 771us/step - loss: 0.4699 - val_loss: 0.5652\n",
      "Epoch 213/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4851 - val_loss: 0.6109\n",
      "Epoch 214/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.4907 - val_loss: 0.5851\n",
      "Epoch 215/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4838 - val_loss: 0.5635\n",
      "Epoch 216/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4815 - val_loss: 0.5866\n",
      "Epoch 217/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4723 - val_loss: 0.5468\n",
      "Epoch 218/1000\n",
      "165/165 [==============================] - 0s 797us/step - loss: 0.4652 - val_loss: 0.5440\n",
      "Epoch 219/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4719 - val_loss: 0.5539\n",
      "Epoch 220/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4636 - val_loss: 0.5546\n",
      "Epoch 221/1000\n",
      "165/165 [==============================] - 0s 703us/step - loss: 0.4685 - val_loss: 0.5594\n",
      "Epoch 222/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4696 - val_loss: 0.6063\n",
      "Epoch 223/1000\n",
      "165/165 [==============================] - 0s 747us/step - loss: 0.4757 - val_loss: 0.5371\n",
      "Epoch 224/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4684 - val_loss: 0.5802\n",
      "Epoch 225/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4738 - val_loss: 0.5589\n",
      "Epoch 226/1000\n",
      "165/165 [==============================] - 0s 686us/step - loss: 0.4705 - val_loss: 0.5526\n",
      "Epoch 227/1000\n",
      "165/165 [==============================] - 0s 748us/step - loss: 0.4649 - val_loss: 0.5573\n",
      "Epoch 228/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4763 - val_loss: 0.5547\n",
      "Epoch 229/1000\n",
      "165/165 [==============================] - 0s 788us/step - loss: 0.4616 - val_loss: 0.5272\n",
      "Epoch 230/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4606 - val_loss: 0.5605\n",
      "Epoch 231/1000\n",
      "165/165 [==============================] - 0s 710us/step - loss: 0.4773 - val_loss: 0.5465\n",
      "Epoch 232/1000\n",
      "165/165 [==============================] - 0s 687us/step - loss: 0.4705 - val_loss: 0.5329\n",
      "Epoch 233/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4616 - val_loss: 0.5883\n",
      "Epoch 234/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4737 - val_loss: 0.5733\n",
      "Epoch 235/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4662 - val_loss: 0.5418\n",
      "Epoch 236/1000\n",
      "165/165 [==============================] - 0s 690us/step - loss: 0.4642 - val_loss: 0.5556\n",
      "Epoch 237/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4625 - val_loss: 0.5465\n",
      "Epoch 238/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4610 - val_loss: 0.5501\n",
      "Epoch 239/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4663 - val_loss: 0.5494\n",
      "Epoch 240/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4573 - val_loss: 0.5388\n",
      "Epoch 241/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4611 - val_loss: 0.6660\n",
      "Epoch 242/1000\n",
      "165/165 [==============================] - 0s 768us/step - loss: 0.4653 - val_loss: 0.5869\n",
      "Epoch 243/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4587 - val_loss: 0.5321\n",
      "Epoch 244/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.4549 - val_loss: 0.5993\n",
      "Epoch 245/1000\n",
      "165/165 [==============================] - 0s 790us/step - loss: 0.4660 - val_loss: 0.5225\n",
      "Epoch 246/1000\n",
      "165/165 [==============================] - 0s 732us/step - loss: 0.4629 - val_loss: 0.5493\n",
      "Epoch 247/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4573 - val_loss: 0.5437\n",
      "Epoch 248/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.4602 - val_loss: 0.5750\n",
      "Epoch 249/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4611 - val_loss: 0.5468\n",
      "Epoch 250/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.4674 - val_loss: 0.5369\n",
      "Epoch 251/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4622 - val_loss: 0.6025\n",
      "Epoch 252/1000\n",
      "165/165 [==============================] - 0s 793us/step - loss: 0.4602 - val_loss: 0.5212\n",
      "Epoch 253/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4552 - val_loss: 0.5255\n",
      "Epoch 254/1000\n",
      "165/165 [==============================] - 0s 804us/step - loss: 0.4600 - val_loss: 0.5125\n",
      "Epoch 255/1000\n",
      "165/165 [==============================] - 0s 768us/step - loss: 0.4584 - val_loss: 0.5656\n",
      "Epoch 256/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4570 - val_loss: 0.5371\n",
      "Epoch 257/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4504 - val_loss: 0.5320\n",
      "Epoch 258/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4481 - val_loss: 0.5786\n",
      "Epoch 259/1000\n",
      "165/165 [==============================] - 0s 783us/step - loss: 0.4623 - val_loss: 0.5111\n",
      "Epoch 260/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.4522 - val_loss: 0.5195\n",
      "Epoch 261/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4532 - val_loss: 0.5129\n",
      "Epoch 262/1000\n",
      "165/165 [==============================] - 0s 731us/step - loss: 0.4508 - val_loss: 0.4970\n",
      "Epoch 263/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4481 - val_loss: 0.5452\n",
      "Epoch 264/1000\n",
      "165/165 [==============================] - 0s 679us/step - loss: 0.4538 - val_loss: 0.5059\n",
      "Epoch 265/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4445 - val_loss: 0.5552\n",
      "Epoch 266/1000\n",
      "165/165 [==============================] - 0s 717us/step - loss: 0.4593 - val_loss: 0.5125\n",
      "Epoch 267/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4483 - val_loss: 0.5949\n",
      "Epoch 268/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4537 - val_loss: 0.5027\n",
      "Epoch 269/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4439 - val_loss: 0.5237\n",
      "Epoch 270/1000\n",
      "165/165 [==============================] - 0s 772us/step - loss: 0.4476 - val_loss: 0.5043\n",
      "Epoch 271/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4378 - val_loss: 0.6105\n",
      "Epoch 272/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4616 - val_loss: 0.5553\n",
      "Epoch 273/1000\n",
      "165/165 [==============================] - 0s 697us/step - loss: 0.4483 - val_loss: 0.5479\n",
      "Epoch 274/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4389 - val_loss: 0.5032\n",
      "Epoch 275/1000\n",
      "165/165 [==============================] - 0s 702us/step - loss: 0.4352 - val_loss: 0.5146\n",
      "Epoch 276/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4502 - val_loss: 0.4988\n",
      "Epoch 277/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4612 - val_loss: 0.5125\n",
      "Epoch 278/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4328 - val_loss: 0.5301\n",
      "Epoch 279/1000\n",
      "165/165 [==============================] - 0s 794us/step - loss: 0.4500 - val_loss: 0.4907\n",
      "Epoch 280/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.4379 - val_loss: 0.5036\n",
      "Epoch 281/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4443 - val_loss: 0.5537\n",
      "Epoch 282/1000\n",
      "165/165 [==============================] - 0s 727us/step - loss: 0.4409 - val_loss: 0.4967\n",
      "Epoch 283/1000\n",
      "165/165 [==============================] - 0s 762us/step - loss: 0.4356 - val_loss: 0.5154\n",
      "Epoch 284/1000\n",
      "165/165 [==============================] - 0s 694us/step - loss: 0.4397 - val_loss: 0.5269\n",
      "Epoch 285/1000\n",
      "165/165 [==============================] - 0s 712us/step - loss: 0.4449 - val_loss: 0.5051\n",
      "Epoch 286/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4385 - val_loss: 0.4989\n",
      "Epoch 287/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4477 - val_loss: 0.4986\n",
      "Epoch 288/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4381 - val_loss: 0.5302\n",
      "Epoch 289/1000\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.4580 - val_loss: 0.5161\n",
      "Epoch 290/1000\n",
      "165/165 [==============================] - 0s 708us/step - loss: 0.4433 - val_loss: 0.5382\n",
      "Epoch 291/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4372 - val_loss: 0.5162\n",
      "Epoch 292/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4364 - val_loss: 0.4917\n",
      "Epoch 293/1000\n",
      "165/165 [==============================] - 0s 789us/step - loss: 0.4300 - val_loss: 0.4851\n",
      "Epoch 294/1000\n",
      "165/165 [==============================] - 0s 717us/step - loss: 0.4377 - val_loss: 0.5057\n",
      "Epoch 295/1000\n",
      "165/165 [==============================] - 0s 700us/step - loss: 0.4288 - val_loss: 0.5342\n",
      "Epoch 296/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4543 - val_loss: 0.5099\n",
      "Epoch 297/1000\n",
      "165/165 [==============================] - 0s 774us/step - loss: 0.4323 - val_loss: 0.5047\n",
      "Epoch 298/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4403 - val_loss: 0.5296\n",
      "Epoch 299/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4375 - val_loss: 0.5009\n",
      "Epoch 300/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4283 - val_loss: 0.5150\n",
      "Epoch 301/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4317 - val_loss: 0.4909\n",
      "Epoch 302/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4255 - val_loss: 0.5211\n",
      "Epoch 303/1000\n",
      "165/165 [==============================] - 0s 690us/step - loss: 0.4394 - val_loss: 0.5305\n",
      "Epoch 304/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4358 - val_loss: 0.4986\n",
      "Epoch 305/1000\n",
      "165/165 [==============================] - 0s 688us/step - loss: 0.4370 - val_loss: 0.5009\n",
      "Epoch 306/1000\n",
      "165/165 [==============================] - 0s 681us/step - loss: 0.4263 - val_loss: 0.4992\n",
      "Epoch 307/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4340 - val_loss: 0.4955\n",
      "Epoch 308/1000\n",
      "165/165 [==============================] - 0s 688us/step - loss: 0.4350 - val_loss: 0.5018\n",
      "Epoch 309/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4398 - val_loss: 0.5502\n",
      "Epoch 310/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4328 - val_loss: 0.5391\n",
      "Epoch 311/1000\n",
      "165/165 [==============================] - 0s 774us/step - loss: 0.4456 - val_loss: 0.4882\n",
      "Epoch 312/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4328 - val_loss: 0.4867\n",
      "Epoch 313/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4276 - val_loss: 0.5052\n",
      "Epoch 314/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4207 - val_loss: 0.5263\n",
      "Epoch 315/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4259 - val_loss: 0.5292\n",
      "Epoch 316/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4194 - val_loss: 0.4934\n",
      "Epoch 317/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.4466 - val_loss: 0.5927\n",
      "Epoch 318/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4330 - val_loss: 0.5281\n",
      "Epoch 319/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4351 - val_loss: 0.4994\n",
      "Epoch 320/1000\n",
      "165/165 [==============================] - 0s 697us/step - loss: 0.4278 - val_loss: 0.5254\n",
      "Epoch 321/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4343 - val_loss: 0.5184\n",
      "Epoch 322/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4368 - val_loss: 0.5689\n",
      "Epoch 323/1000\n",
      "165/165 [==============================] - 0s 805us/step - loss: 0.4417 - val_loss: 0.4777\n",
      "Epoch 324/1000\n",
      "165/165 [==============================] - 0s 763us/step - loss: 0.4224 - val_loss: 0.4958\n",
      "Epoch 325/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.4243 - val_loss: 0.5123\n",
      "Epoch 326/1000\n",
      "165/165 [==============================] - 0s 682us/step - loss: 0.4260 - val_loss: 0.5223\n",
      "Epoch 327/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4272 - val_loss: 0.4912\n",
      "Epoch 328/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4281 - val_loss: 0.5233\n",
      "Epoch 329/1000\n",
      "165/165 [==============================] - 0s 683us/step - loss: 0.4402 - val_loss: 0.4816\n",
      "Epoch 330/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.4182 - val_loss: 0.4879\n",
      "Epoch 331/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.4334 - val_loss: 0.5431\n",
      "Epoch 332/1000\n",
      "165/165 [==============================] - 0s 736us/step - loss: 0.4177 - val_loss: 0.5179\n",
      "Epoch 333/1000\n",
      "165/165 [==============================] - 0s 677us/step - loss: 0.4214 - val_loss: 0.5144\n",
      "Epoch 334/1000\n",
      "165/165 [==============================] - 0s 670us/step - loss: 0.4415 - val_loss: 0.4989\n",
      "Epoch 335/1000\n",
      "165/165 [==============================] - 0s 673us/step - loss: 0.4261 - val_loss: 0.5022\n",
      "Epoch 336/1000\n",
      "165/165 [==============================] - 0s 770us/step - loss: 0.4192 - val_loss: 0.5150\n",
      "Epoch 337/1000\n",
      "165/165 [==============================] - 0s 686us/step - loss: 0.4189 - val_loss: 0.5068\n",
      "Epoch 338/1000\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.4261 - val_loss: 0.5267\n",
      "Epoch 339/1000\n",
      "165/165 [==============================] - 0s 732us/step - loss: 0.4167 - val_loss: 0.4895\n",
      "Epoch 340/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4207 - val_loss: 0.5063\n",
      "Epoch 341/1000\n",
      "165/165 [==============================] - 0s 704us/step - loss: 0.4274 - val_loss: 0.5032\n",
      "Epoch 342/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.4178 - val_loss: 0.5198\n",
      "Epoch 343/1000\n",
      "165/165 [==============================] - 0s 730us/step - loss: 0.4312 - val_loss: 0.4886\n",
      "Epoch 344/1000\n",
      "165/165 [==============================] - 0s 689us/step - loss: 0.4209 - val_loss: 0.4966\n",
      "Epoch 345/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.4115 - val_loss: 0.5101\n",
      "Epoch 346/1000\n",
      "165/165 [==============================] - 0s 804us/step - loss: 0.4422 - val_loss: 0.4753\n",
      "Epoch 347/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4233 - val_loss: 0.5078\n",
      "Epoch 348/1000\n",
      "165/165 [==============================] - 0s 695us/step - loss: 0.4267 - val_loss: 0.5095\n",
      "Epoch 349/1000\n",
      "165/165 [==============================] - 0s 735us/step - loss: 0.4258 - val_loss: 0.5018\n",
      "Epoch 350/1000\n",
      "165/165 [==============================] - 0s 805us/step - loss: 0.4225 - val_loss: 0.5036\n",
      "Epoch 351/1000\n",
      "165/165 [==============================] - 0s 718us/step - loss: 0.4294 - val_loss: 0.4948\n",
      "Epoch 352/1000\n",
      "165/165 [==============================] - 0s 726us/step - loss: 0.4106 - val_loss: 0.5070\n",
      "Epoch 353/1000\n",
      "165/165 [==============================] - 0s 715us/step - loss: 0.4172 - val_loss: 0.4831\n",
      "Epoch 354/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4219 - val_loss: 0.4815\n",
      "Epoch 355/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4140 - val_loss: 0.5236\n",
      "Epoch 356/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4129 - val_loss: 0.4824\n",
      "Epoch 357/1000\n",
      "165/165 [==============================] - 0s 793us/step - loss: 0.4196 - val_loss: 0.4742\n",
      "Epoch 358/1000\n",
      "165/165 [==============================] - 0s 763us/step - loss: 0.4163 - val_loss: 0.4654\n",
      "Epoch 359/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4080 - val_loss: 0.6078\n",
      "Epoch 360/1000\n",
      "165/165 [==============================] - 0s 708us/step - loss: 0.4305 - val_loss: 0.4936\n",
      "Epoch 361/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4037 - val_loss: 0.5279\n",
      "Epoch 362/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4194 - val_loss: 0.4789\n",
      "Epoch 363/1000\n",
      "165/165 [==============================] - 0s 781us/step - loss: 0.4083 - val_loss: 0.5024\n",
      "Epoch 364/1000\n",
      "165/165 [==============================] - 0s 739us/step - loss: 0.4195 - val_loss: 0.5383\n",
      "Epoch 365/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.4149 - val_loss: 0.5279\n",
      "Epoch 366/1000\n",
      "165/165 [==============================] - 0s 702us/step - loss: 0.4221 - val_loss: 0.5710\n",
      "Epoch 367/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.4234 - val_loss: 0.5107\n",
      "Epoch 368/1000\n",
      "165/165 [==============================] - 0s 724us/step - loss: 0.4152 - val_loss: 0.4873\n",
      "Epoch 369/1000\n",
      "165/165 [==============================] - 0s 705us/step - loss: 0.4074 - val_loss: 0.5453\n",
      "Epoch 370/1000\n",
      "165/165 [==============================] - 0s 721us/step - loss: 0.4154 - val_loss: 0.4736\n",
      "Epoch 371/1000\n",
      "165/165 [==============================] - 0s 744us/step - loss: 0.4059 - val_loss: 0.5173\n",
      "Epoch 372/1000\n",
      "165/165 [==============================] - 0s 703us/step - loss: 0.4250 - val_loss: 0.4898\n",
      "Epoch 373/1000\n",
      "165/165 [==============================] - 0s 724us/step - loss: 0.4098 - val_loss: 0.5027\n",
      "Epoch 374/1000\n",
      "165/165 [==============================] - 0s 730us/step - loss: 0.4234 - val_loss: 0.5576\n",
      "Epoch 375/1000\n",
      "165/165 [==============================] - 0s 822us/step - loss: 0.4246 - val_loss: 0.4776\n",
      "Epoch 376/1000\n",
      "165/165 [==============================] - 0s 808us/step - loss: 0.4150 - val_loss: 0.5141\n",
      "Epoch 377/1000\n",
      "165/165 [==============================] - 0s 811us/step - loss: 0.4200 - val_loss: 0.5126\n",
      "Epoch 378/1000\n",
      "165/165 [==============================] - 0s 756us/step - loss: 0.4242 - val_loss: 0.5543\n",
      "Epoch 379/1000\n",
      "165/165 [==============================] - 0s 738us/step - loss: 0.4169 - val_loss: 0.4961\n",
      "Epoch 380/1000\n",
      "165/165 [==============================] - 0s 738us/step - loss: 0.4020 - val_loss: 0.5303\n",
      "Epoch 381/1000\n",
      "165/165 [==============================] - 0s 713us/step - loss: 0.4162 - val_loss: 0.5076\n",
      "Epoch 382/1000\n",
      "165/165 [==============================] - 0s 723us/step - loss: 0.4159 - val_loss: 0.4937\n",
      "Epoch 383/1000\n",
      "165/165 [==============================] - 0s 745us/step - loss: 0.4087 - val_loss: 0.5377\n",
      "Epoch 384/1000\n",
      "165/165 [==============================] - 0s 767us/step - loss: 0.4060 - val_loss: 0.5066\n",
      "Epoch 385/1000\n",
      "165/165 [==============================] - 0s 776us/step - loss: 0.4077 - val_loss: 0.4805\n",
      "Epoch 386/1000\n",
      "165/165 [==============================] - 0s 717us/step - loss: 0.4070 - val_loss: 0.4953\n",
      "Epoch 387/1000\n",
      "165/165 [==============================] - 0s 733us/step - loss: 0.4118 - val_loss: 0.4754\n",
      "Epoch 388/1000\n",
      "165/165 [==============================] - 0s 738us/step - loss: 0.4102 - val_loss: 0.5171\n",
      "Epoch 389/1000\n",
      "165/165 [==============================] - 0s 726us/step - loss: 0.4202 - val_loss: 0.4874\n",
      "Epoch 390/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.3993 - val_loss: 0.4670\n",
      "Epoch 391/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4140 - val_loss: 0.4967\n",
      "Epoch 392/1000\n",
      "165/165 [==============================] - 0s 722us/step - loss: 0.4054 - val_loss: 0.4756\n",
      "Epoch 393/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4100 - val_loss: 0.4807\n",
      "Epoch 394/1000\n",
      "165/165 [==============================] - 0s 732us/step - loss: 0.4045 - val_loss: 0.5211\n",
      "Epoch 395/1000\n",
      "165/165 [==============================] - 0s 720us/step - loss: 0.4135 - val_loss: 0.4926\n",
      "Epoch 396/1000\n",
      "165/165 [==============================] - 0s 829us/step - loss: 0.4050 - val_loss: 0.4750\n",
      "Epoch 397/1000\n",
      "165/165 [==============================] - 0s 707us/step - loss: 0.4193 - val_loss: 0.5018\n",
      "Epoch 398/1000\n",
      "165/165 [==============================] - 0s 734us/step - loss: 0.4158 - val_loss: 0.4824\n",
      "Epoch 399/1000\n",
      "165/165 [==============================] - 0s 726us/step - loss: 0.4024 - val_loss: 0.5037\n",
      "Epoch 400/1000\n",
      "165/165 [==============================] - 0s 701us/step - loss: 0.4057 - val_loss: 0.4684\n",
      "Epoch 401/1000\n",
      "165/165 [==============================] - 0s 748us/step - loss: 0.4006 - val_loss: 0.5370\n",
      "Epoch 402/1000\n",
      "165/165 [==============================] - 0s 732us/step - loss: 0.4133 - val_loss: 0.4923\n",
      "Epoch 403/1000\n",
      "165/165 [==============================] - 0s 744us/step - loss: 0.4219 - val_loss: 0.4916\n",
      "Epoch 404/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.5141\n",
      "Epoch 405/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.5198\n",
      "Epoch 406/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.5169\n",
      "Epoch 407/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.4557\n",
      "Epoch 408/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.4778\n",
      "Epoch 409/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.4820\n",
      "Epoch 410/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.5023\n",
      "Epoch 411/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.4727\n",
      "Epoch 412/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4036 - val_loss: 0.4783\n",
      "Epoch 413/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4818\n",
      "Epoch 414/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.5096\n",
      "Epoch 415/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.4980\n",
      "Epoch 416/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4733\n",
      "Epoch 417/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.5044\n",
      "Epoch 418/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4883\n",
      "Epoch 419/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4210 - val_loss: 0.5482\n",
      "Epoch 420/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.4635\n",
      "Epoch 421/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4760\n",
      "Epoch 422/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.5606\n",
      "Epoch 423/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.4671\n",
      "Epoch 424/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.5276\n",
      "Epoch 425/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.5121\n",
      "Epoch 426/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4697\n",
      "Epoch 427/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.5297\n",
      "Epoch 428/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4842\n",
      "Epoch 429/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4781\n",
      "Epoch 430/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3986 - val_loss: 0.4770\n",
      "Epoch 431/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4847\n",
      "Epoch 432/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4842\n",
      "Epoch 433/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.4680\n",
      "Epoch 434/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4946\n",
      "Epoch 435/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 0.5683\n",
      "Epoch 436/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.4553\n",
      "Epoch 437/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4612\n",
      "Epoch 438/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.4890\n",
      "Epoch 439/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.4876\n",
      "Epoch 440/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.4712\n",
      "Epoch 441/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.5038\n",
      "Epoch 442/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4958\n",
      "Epoch 443/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.4800\n",
      "Epoch 444/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3946 - val_loss: 0.5052\n",
      "Epoch 445/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.4989\n",
      "Epoch 446/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4710\n",
      "Epoch 447/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.5048\n",
      "Epoch 448/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.5111\n",
      "Epoch 449/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4859\n",
      "Epoch 450/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.4899\n",
      "Epoch 451/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4798\n",
      "Epoch 452/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.5025\n",
      "Epoch 453/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4966\n",
      "Epoch 454/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4815\n",
      "Epoch 455/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.5662\n",
      "Epoch 456/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.4801\n",
      "Epoch 457/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3986 - val_loss: 0.4716\n",
      "Epoch 458/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.5542\n",
      "Epoch 459/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.4639\n",
      "Epoch 460/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4863\n",
      "Epoch 461/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.5206\n",
      "Epoch 462/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4642\n",
      "Epoch 463/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4664\n",
      "Epoch 464/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.4628\n",
      "Epoch 465/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4847\n",
      "Epoch 466/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 0.4870\n",
      "Epoch 467/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.4610\n",
      "Epoch 468/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.5011\n",
      "Epoch 469/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.4553\n",
      "Epoch 470/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.5176\n",
      "Epoch 471/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3960 - val_loss: 0.4655\n",
      "Epoch 472/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.4608\n",
      "Epoch 473/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.4822\n",
      "Epoch 474/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4635\n",
      "Epoch 475/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.5183\n",
      "Epoch 476/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4714\n",
      "Epoch 477/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.4710\n",
      "Epoch 478/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.4741\n",
      "Epoch 479/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.4911\n",
      "Epoch 480/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.5375\n",
      "Epoch 481/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.5190\n",
      "Epoch 482/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.5198\n",
      "Epoch 483/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4771\n",
      "Epoch 484/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.4558\n",
      "Epoch 485/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4599\n",
      "Epoch 486/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.4793\n",
      "Epoch 487/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.5208\n",
      "Epoch 488/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4668\n",
      "Epoch 489/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.5134\n",
      "Epoch 490/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 0.5617\n",
      "Epoch 491/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.5592\n",
      "Epoch 492/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.4743\n",
      "Epoch 493/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4672\n",
      "Epoch 494/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.4691\n",
      "Epoch 495/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4586\n",
      "Epoch 496/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.4779\n",
      "Epoch 497/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.4657\n",
      "Epoch 498/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 0.4684\n",
      "Epoch 499/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.5125\n",
      "Epoch 500/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.5010\n",
      "Epoch 501/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.4839\n",
      "Epoch 502/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4608\n",
      "Epoch 503/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.4658\n",
      "Epoch 504/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.5583\n",
      "Epoch 505/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.4999\n",
      "Epoch 506/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4593\n",
      "Epoch 507/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.5191\n",
      "Epoch 508/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.4576\n",
      "Epoch 509/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4666\n",
      "Epoch 510/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4836\n",
      "Epoch 511/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4541\n",
      "Epoch 512/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4855\n",
      "Epoch 513/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.4777\n",
      "Epoch 514/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.4799\n",
      "Epoch 515/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4548\n",
      "Epoch 516/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4613\n",
      "Epoch 517/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.4879\n",
      "Epoch 518/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.4660\n",
      "Epoch 519/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.5220\n",
      "Epoch 520/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3940 - val_loss: 0.4790\n",
      "Epoch 521/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4933\n",
      "Epoch 522/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4625\n",
      "Epoch 523/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.4893\n",
      "Epoch 524/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.4991\n",
      "Epoch 525/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4610\n",
      "Epoch 526/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3940 - val_loss: 0.4524\n",
      "Epoch 527/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4938\n",
      "Epoch 528/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4628\n",
      "Epoch 529/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4534\n",
      "Epoch 530/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.5147\n",
      "Epoch 531/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.5021\n",
      "Epoch 532/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.5280\n",
      "Epoch 533/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4843\n",
      "Epoch 534/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4981\n",
      "Epoch 535/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.4871\n",
      "Epoch 536/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.5052\n",
      "Epoch 537/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.5125\n",
      "Epoch 538/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.5411\n",
      "Epoch 539/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.5250\n",
      "Epoch 540/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3904 - val_loss: 0.4958\n",
      "Epoch 541/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.4910\n",
      "Epoch 542/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.4604\n",
      "Epoch 543/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.4879\n",
      "Epoch 544/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4839\n",
      "Epoch 545/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.4897\n",
      "Epoch 546/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4944\n",
      "Epoch 547/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4822\n",
      "Epoch 548/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4714\n",
      "Epoch 549/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4862\n",
      "Epoch 550/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.4686\n",
      "Epoch 551/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.4841\n",
      "Epoch 552/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4752\n",
      "Epoch 553/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4946\n",
      "Epoch 554/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 0.4758\n",
      "Epoch 555/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.5041\n",
      "Epoch 556/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.5034\n",
      "Epoch 557/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.4647\n",
      "Epoch 558/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4828\n",
      "Epoch 559/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.4913\n",
      "Epoch 560/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.4668\n",
      "Epoch 561/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4925\n",
      "Epoch 562/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.4504\n",
      "Epoch 563/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4797\n",
      "Epoch 564/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4611\n",
      "Epoch 565/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4768\n",
      "Epoch 566/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4467\n",
      "Epoch 567/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4549\n",
      "Epoch 568/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.4628\n",
      "Epoch 569/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.5132\n",
      "Epoch 570/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4627\n",
      "Epoch 571/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4547\n",
      "Epoch 572/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.4955\n",
      "Epoch 573/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4638\n",
      "Epoch 574/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4828\n",
      "Epoch 575/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3919 - val_loss: 0.5166\n",
      "Epoch 576/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4509\n",
      "Epoch 577/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.4511\n",
      "Epoch 578/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4477\n",
      "Epoch 579/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.4917\n",
      "Epoch 580/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4853\n",
      "Epoch 581/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.4913\n",
      "Epoch 582/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.4598\n",
      "Epoch 583/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.4495\n",
      "Epoch 584/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3814 - val_loss: 0.4621\n",
      "Epoch 585/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4535\n",
      "Epoch 586/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.4617\n",
      "Epoch 587/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.4577\n",
      "Epoch 588/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4680\n",
      "Epoch 589/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4694\n",
      "Epoch 590/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4863\n",
      "Epoch 591/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.4802\n",
      "Epoch 592/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.4683\n",
      "Epoch 593/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4713\n",
      "Epoch 594/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.4810\n",
      "Epoch 595/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.5138\n",
      "Epoch 596/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.4446\n",
      "Epoch 597/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.4608\n",
      "Epoch 598/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4567\n",
      "Epoch 599/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.4910\n",
      "Epoch 600/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.4965\n",
      "Epoch 601/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.4750\n",
      "Epoch 602/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4570\n",
      "Epoch 603/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.4616\n",
      "Epoch 604/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.4584\n",
      "Epoch 605/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4742\n",
      "Epoch 606/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4811\n",
      "Epoch 607/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.5062\n",
      "Epoch 608/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.4708\n",
      "Epoch 609/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3960 - val_loss: 0.5134\n",
      "Epoch 610/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.5530\n",
      "Epoch 611/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.4590\n",
      "Epoch 612/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.4778\n",
      "Epoch 613/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4624\n",
      "Epoch 614/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4582\n",
      "Epoch 615/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.4552\n",
      "Epoch 616/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3813 - val_loss: 0.4849\n",
      "Epoch 617/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.4677\n",
      "Epoch 618/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4623\n",
      "Epoch 619/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.5202\n",
      "Epoch 620/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4506\n",
      "Epoch 621/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4772\n",
      "Epoch 622/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4544\n",
      "Epoch 623/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.4716\n",
      "Epoch 624/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.4888\n",
      "Epoch 625/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4582\n",
      "Epoch 626/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.4532\n",
      "Epoch 627/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.4891\n",
      "Epoch 628/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.4738\n",
      "Epoch 629/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.4581\n",
      "Epoch 630/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.4663\n",
      "Epoch 631/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.4520\n",
      "Epoch 632/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 0.4890\n",
      "Epoch 633/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4518\n",
      "Epoch 634/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4579\n",
      "Epoch 635/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4749\n",
      "Epoch 636/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.4528\n",
      "Epoch 637/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4568\n",
      "Epoch 638/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4577\n",
      "Epoch 639/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.4687\n",
      "Epoch 640/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.4519\n",
      "Epoch 641/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4524\n",
      "Epoch 642/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.4863\n",
      "Epoch 643/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4658\n",
      "Epoch 644/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4731\n",
      "Epoch 645/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4638\n",
      "Epoch 646/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4714\n",
      "Epoch 647/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.4826\n",
      "Epoch 648/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.4841\n",
      "Epoch 649/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4515\n",
      "Epoch 650/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4886\n",
      "Epoch 651/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4908\n",
      "Epoch 652/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4654\n",
      "Epoch 653/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.4442\n",
      "Epoch 654/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.4600\n",
      "Epoch 655/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4810\n",
      "Epoch 656/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.4476\n",
      "Epoch 657/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4473\n",
      "Epoch 658/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4551\n",
      "Epoch 659/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.4858\n",
      "Epoch 660/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4890\n",
      "Epoch 661/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.4380\n",
      "Epoch 662/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4760\n",
      "Epoch 663/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.5036\n",
      "Epoch 664/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.5039\n",
      "Epoch 665/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.4629\n",
      "Epoch 666/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4746\n",
      "Epoch 667/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.5460\n",
      "Epoch 668/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.4474\n",
      "Epoch 669/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.5287\n",
      "Epoch 670/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.4681\n",
      "Epoch 671/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.4539\n",
      "Epoch 672/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.4589\n",
      "Epoch 673/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4609\n",
      "Epoch 674/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.4422\n",
      "Epoch 675/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4450\n",
      "Epoch 676/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.5522\n",
      "Epoch 677/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.5308\n",
      "Epoch 678/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.4755\n",
      "Epoch 679/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.4503\n",
      "Epoch 680/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4592\n",
      "Epoch 681/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.4578\n",
      "Epoch 682/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.4673\n",
      "Epoch 683/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4612\n",
      "Epoch 684/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.4712\n",
      "Epoch 685/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.4651\n",
      "Epoch 686/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.4478\n",
      "Epoch 687/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.4824\n",
      "Epoch 688/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4784\n",
      "Epoch 689/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 0.5005\n",
      "Epoch 690/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.4868\n",
      "Epoch 691/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.4735\n",
      "Epoch 692/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.4752\n",
      "Epoch 693/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.4439\n",
      "Epoch 694/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.4479\n",
      "Epoch 695/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4674\n",
      "Epoch 696/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4656\n",
      "Epoch 697/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4673\n",
      "Epoch 698/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.4622\n",
      "Epoch 699/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.5180\n",
      "Epoch 700/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.4615\n",
      "Epoch 701/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.4684\n",
      "Epoch 702/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4885\n",
      "Epoch 703/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4829\n",
      "Epoch 704/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4811\n",
      "Epoch 705/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4746\n",
      "Epoch 706/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4731\n",
      "Epoch 707/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4563\n",
      "Epoch 708/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4866\n",
      "Epoch 709/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4520\n",
      "Epoch 710/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.5170\n",
      "Epoch 711/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4874\n",
      "Epoch 712/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4584\n",
      "Epoch 713/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.4326\n",
      "Epoch 714/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4692\n",
      "Epoch 715/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.4548\n",
      "Epoch 716/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4454\n",
      "Epoch 717/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.4934\n",
      "Epoch 718/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4651\n",
      "Epoch 719/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.4376\n",
      "Epoch 720/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4461\n",
      "Epoch 721/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.4547\n",
      "Epoch 722/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.5155\n",
      "Epoch 723/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.4598\n",
      "Epoch 724/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4975\n",
      "Epoch 725/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4964\n",
      "Epoch 726/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.4794\n",
      "Epoch 727/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.4616\n",
      "Epoch 728/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4541\n",
      "Epoch 729/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.4783\n",
      "Epoch 730/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4586\n",
      "Epoch 731/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.4619\n",
      "Epoch 732/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4270\n",
      "Epoch 733/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.4604\n",
      "Epoch 734/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.5121\n",
      "Epoch 735/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.4780\n",
      "Epoch 736/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.4791\n",
      "Epoch 737/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.5059\n",
      "Epoch 738/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4479\n",
      "Epoch 739/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4304\n",
      "Epoch 740/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.4476\n",
      "Epoch 741/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4394\n",
      "Epoch 742/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 0.4421\n",
      "Epoch 743/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.4581\n",
      "Epoch 744/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4840\n",
      "Epoch 745/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.5331\n",
      "Epoch 746/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4832\n",
      "Epoch 747/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4757\n",
      "Epoch 748/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4638\n",
      "Epoch 749/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.4443\n",
      "Epoch 750/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.4892\n",
      "Epoch 751/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.4483\n",
      "Epoch 752/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.5001\n",
      "Epoch 753/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4681\n",
      "Epoch 754/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.4898\n",
      "Epoch 755/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4596\n",
      "Epoch 756/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.4572\n",
      "Epoch 757/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4465\n",
      "Epoch 758/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4840\n",
      "Epoch 759/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4586\n",
      "Epoch 760/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4601\n",
      "Epoch 761/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3878 - val_loss: 0.4516\n",
      "Epoch 762/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4702\n",
      "Epoch 763/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4800\n",
      "Epoch 764/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.4453\n",
      "Epoch 765/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4409\n",
      "Epoch 766/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.4915\n",
      "Epoch 767/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.5299\n",
      "Epoch 768/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4422\n",
      "Epoch 769/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.4422\n",
      "Epoch 770/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.4693\n",
      "Epoch 771/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.4528\n",
      "Epoch 772/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4341\n",
      "Epoch 773/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.4524\n",
      "Epoch 774/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4949\n",
      "Epoch 775/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4540\n",
      "Epoch 776/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.4665\n",
      "Epoch 777/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.5511\n",
      "Epoch 778/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4690\n",
      "Epoch 779/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.4485\n",
      "Epoch 780/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4747\n",
      "Epoch 781/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.4673\n",
      "Epoch 782/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.4317\n",
      "Epoch 783/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4482\n",
      "Epoch 784/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.4685\n",
      "Epoch 785/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4215\n",
      "Epoch 786/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4552\n",
      "Epoch 787/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.4665\n",
      "Epoch 788/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.4326\n",
      "Epoch 789/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.4342\n",
      "Epoch 790/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4785\n",
      "Epoch 791/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.4649\n",
      "Epoch 792/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.4643\n",
      "Epoch 793/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4515\n",
      "Epoch 794/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.4424\n",
      "Epoch 795/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.4721\n",
      "Epoch 796/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.4436\n",
      "Epoch 797/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3647 - val_loss: 0.4665\n",
      "Epoch 798/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.4750\n",
      "Epoch 799/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.5065\n",
      "Epoch 800/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.4373\n",
      "Epoch 801/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4363\n",
      "Epoch 802/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4791\n",
      "Epoch 803/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4421\n",
      "Epoch 804/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3643 - val_loss: 0.4366\n",
      "Epoch 805/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.4613\n",
      "Epoch 806/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.4515\n",
      "Epoch 807/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.4513\n",
      "Epoch 808/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.5081\n",
      "Epoch 809/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.4501\n",
      "Epoch 810/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.4458\n",
      "Epoch 811/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.4871\n",
      "Epoch 812/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.4458\n",
      "Epoch 813/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4545\n",
      "Epoch 814/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.4396\n",
      "Epoch 815/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4539\n",
      "Epoch 816/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4636\n",
      "Epoch 817/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4896\n",
      "Epoch 818/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.4373\n",
      "Epoch 819/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.5010\n",
      "Epoch 820/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.4481\n",
      "Epoch 821/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.4488\n",
      "Epoch 822/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4288\n",
      "Epoch 823/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4378\n",
      "Epoch 824/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3787 - val_loss: 0.4649\n",
      "Epoch 825/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.4891\n",
      "Epoch 826/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4402\n",
      "Epoch 827/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.4929\n",
      "Epoch 828/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.4594\n",
      "Epoch 829/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.4218\n",
      "Epoch 830/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.4272\n",
      "Epoch 831/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.4461\n",
      "Epoch 832/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.4660\n",
      "Epoch 833/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.4532\n",
      "Epoch 834/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4641\n",
      "Epoch 835/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.4367\n",
      "Epoch 836/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.4512\n",
      "Epoch 837/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.5083\n",
      "Epoch 838/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4495\n",
      "Epoch 839/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.4667\n",
      "Epoch 840/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4548\n",
      "Epoch 841/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.4845\n",
      "Epoch 842/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.5030\n",
      "Epoch 843/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.4410\n",
      "Epoch 844/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4515\n",
      "Epoch 845/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.4412\n",
      "Epoch 846/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.4361\n",
      "Epoch 847/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4945\n",
      "Epoch 848/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.4314\n",
      "Epoch 849/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.5090\n",
      "Epoch 850/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4822\n",
      "Epoch 851/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4757\n",
      "Epoch 852/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3629 - val_loss: 0.4327\n",
      "Epoch 853/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.4451\n",
      "Epoch 854/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.4461\n",
      "Epoch 855/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.4405\n",
      "Epoch 856/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.4380\n",
      "Epoch 857/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4757\n",
      "Epoch 858/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.4463\n",
      "Epoch 859/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.4780\n",
      "Epoch 860/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4417\n",
      "Epoch 861/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.4996\n",
      "Epoch 862/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.4542\n",
      "Epoch 863/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.4689\n",
      "Epoch 864/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4594\n",
      "Epoch 865/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4705\n",
      "Epoch 866/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.4431\n",
      "Epoch 867/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4423\n",
      "Epoch 868/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.4635\n",
      "Epoch 869/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4277\n",
      "Epoch 870/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3628 - val_loss: 0.4506\n",
      "Epoch 871/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.4585\n",
      "Epoch 872/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.4518\n",
      "Epoch 873/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.4326\n",
      "Epoch 874/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4671\n",
      "Epoch 875/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4642\n",
      "Epoch 876/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.4666\n",
      "Epoch 877/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.4370\n",
      "Epoch 878/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.4548\n",
      "Epoch 879/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 0.4396\n",
      "Epoch 880/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.5142\n",
      "Epoch 881/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4350\n",
      "Epoch 882/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.4917\n",
      "Epoch 883/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4922\n",
      "Epoch 884/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4404\n",
      "Epoch 885/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.4313\n",
      "Epoch 886/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.4594\n",
      "Epoch 887/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4582\n",
      "Epoch 888/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.4581\n",
      "Epoch 889/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4720\n",
      "Epoch 890/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4422\n",
      "Epoch 891/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.4615\n",
      "Epoch 892/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.4518\n",
      "Epoch 893/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 0.4342\n",
      "Epoch 894/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3634 - val_loss: 0.4337\n",
      "Epoch 895/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.4927\n",
      "Epoch 896/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.4792\n",
      "Epoch 897/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.4449\n",
      "Epoch 898/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3634 - val_loss: 0.4515\n",
      "Epoch 899/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.4914\n",
      "Epoch 900/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.4344\n",
      "Epoch 901/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4502\n",
      "Epoch 902/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.4297\n",
      "Epoch 903/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.4593\n",
      "Epoch 904/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.4590\n",
      "Epoch 905/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.5202\n",
      "Epoch 906/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.4371\n",
      "Epoch 907/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4610\n",
      "Epoch 908/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4386\n",
      "Epoch 909/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4542\n",
      "Epoch 910/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.4370\n",
      "Epoch 911/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.4498\n",
      "Epoch 912/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.4790\n",
      "Epoch 913/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.4326\n",
      "Epoch 914/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3591 - val_loss: 0.4367\n",
      "Epoch 915/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4670\n",
      "Epoch 916/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.4271\n",
      "Epoch 917/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.4649\n",
      "Epoch 918/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.4504\n",
      "Epoch 919/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4530\n",
      "Epoch 920/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.5018\n",
      "Epoch 921/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.4422\n",
      "Epoch 922/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.4884\n",
      "Epoch 923/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.4629\n",
      "Epoch 924/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.4716\n",
      "Epoch 925/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4932\n",
      "Epoch 926/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.4472\n",
      "Epoch 927/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3600 - val_loss: 0.4492\n",
      "Epoch 928/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.5036\n",
      "Epoch 929/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.5010\n",
      "Epoch 930/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4682\n",
      "Epoch 931/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.4531\n",
      "Epoch 932/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.4486\n",
      "Epoch 933/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.4311\n",
      "Epoch 934/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4548\n",
      "Epoch 935/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.4445\n",
      "Epoch 936/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.4996\n",
      "Epoch 937/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3628 - val_loss: 0.4625\n",
      "Epoch 938/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.4165\n",
      "Epoch 939/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.4593\n",
      "Epoch 940/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.4575\n",
      "Epoch 941/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.5077\n",
      "Epoch 942/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.4732\n",
      "Epoch 943/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.4515\n",
      "Epoch 944/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.4754\n",
      "Epoch 945/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.4401\n",
      "Epoch 946/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.4613\n",
      "Epoch 947/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.4696\n",
      "Epoch 948/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.4532\n",
      "Epoch 949/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.4645\n",
      "Epoch 950/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.4697\n",
      "Epoch 951/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4668\n",
      "Epoch 952/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.5069\n",
      "Epoch 953/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.4491\n",
      "Epoch 954/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.4869\n",
      "Epoch 955/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.4532\n",
      "Epoch 956/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4590\n",
      "Epoch 957/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.4413\n",
      "Epoch 958/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4501\n",
      "Epoch 959/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.4598\n",
      "Epoch 960/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.4431\n",
      "Epoch 961/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3630 - val_loss: 0.5271\n",
      "Epoch 962/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.4623\n",
      "Epoch 963/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.4954\n",
      "Epoch 964/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.4650\n",
      "Epoch 965/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.4617\n",
      "Epoch 966/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4920\n",
      "Epoch 967/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.4717\n",
      "Epoch 968/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.4566\n",
      "Epoch 969/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.4855\n",
      "Epoch 970/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.4798\n",
      "Epoch 971/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.4442\n",
      "Epoch 972/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.4274\n",
      "Epoch 973/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.4791\n",
      "Epoch 974/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.4937\n",
      "Epoch 975/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.4631\n",
      "Epoch 976/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.4515\n",
      "Epoch 977/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.4703\n",
      "Epoch 978/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.4333\n",
      "Epoch 979/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.4302\n",
      "Epoch 980/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.4436\n",
      "Epoch 981/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3567 - val_loss: 0.4255\n",
      "Epoch 982/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.4974\n",
      "Epoch 983/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.4450\n",
      "Epoch 984/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.4507\n",
      "Epoch 985/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4836\n",
      "Epoch 986/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4780\n",
      "Epoch 987/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4329\n",
      "Epoch 988/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4563\n",
      "Epoch 989/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.4328\n",
      "Epoch 990/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.4502\n",
      "Epoch 991/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 0.4270\n",
      "Epoch 992/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.5197\n",
      "Epoch 993/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.4479\n",
      "Epoch 994/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3633 - val_loss: 0.4845\n",
      "Epoch 995/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.4293\n",
      "Epoch 996/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 0.4773\n",
      "Epoch 997/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4503\n",
      "Epoch 998/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 0.5154\n",
      "Epoch 999/1000\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.4944\n",
      "Epoch 1000/1000\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4472\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(None,54)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss=rmse, optimizer='adam')\n",
    "\n",
    "chk_callback = keras.callbacks.ModelCheckpoint(filepath='./tmp/md.h5', save_weights_only=False, monitor='val_loss', mode='min', save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, epochs=1000, validation_data=(X_valid, y_valid), callbacks=[chk_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 15000x20000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(150,200))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(hist.history['loss'][200:400], 'y', label='train_loss')\n",
    "ax.plot(hist.history['val_loss'][200:400], 'r', label='val_loss')\n",
    "\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, None, 32)          1760      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, None, 1)           33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,793\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 414us/step\n",
      "Valid 데이터 RMSE: 0.484\n"
     ]
    }
   ],
   "source": [
    "# valid 데이터 예측 및 평가\n",
    "y_pred_valid = model.predict(X_valid)\n",
    "rmse_valid = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
    "print(f\"Valid 데이터 RMSE: {rmse_valid:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xac in position 38: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m md_new \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mtmp/md.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m y_pred_valid \u001b[39m=\u001b[39m md_new\u001b[39m.\u001b[39mpredict(X_valid)\n\u001b[0;32m      3\u001b[0m rmse_valid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(mean_squared_error(y_valid, y_pred_valid))\n",
      "File \u001b[1;32mc:\\jhs\\miniconda\\envs\\jhs\\Lib\\site-packages\\keras\\saving\\saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    205\u001b[0m         filepath,\n\u001b[0;32m    206\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    207\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    208\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    213\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    214\u001b[0m )\n",
      "File \u001b[1;32mc:\\jhs\\miniconda\\envs\\jhs\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\jhs\\miniconda\\envs\\jhs\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[39m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[39mreturn\u001b[39;00m _pywrap_file_io\u001b[39m.\u001b[39mIsDirectory(compat\u001b[39m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    704\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xac in position 38: invalid start byte"
     ]
    }
   ],
   "source": [
    "md_new = keras.models.load_model('tmp/md.h5')\n",
    "y_pred_valid = md_new.predict(X_valid)\n",
    "rmse_valid = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
    "print(f\"Valid 데이터 RMSE: {rmse_valid:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhs3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
